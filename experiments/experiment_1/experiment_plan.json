{
  "experiment_name": "RF_Baseline_Collision_Prediction",
  "task_type": "Multi-class classification (imbalanced)",
  "target_column": "collisions",
  "experiment_evaluation_metric": "PR-AUC (Precision-Recall Area Under Curve)",
  
  "experiment_preprocessing_steps": "1. Remove identifier column 'driver_id' from both train and test sets. 2. Encode categorical 'month' column using LabelEncoder fitted on train set, applied to both train and test. 3. Handle missing values using median imputation: calculate median for each numeric feature from train set only, apply to both train and test for columns: 'count_trip', 'miles', 'drive_hours', 'count_brakes', 'count_accelarations', 'time_speeding_hours', 'time_phoneuse_hours', 'highway_miles', 'night_drive_hrs', 'maximum_speed'. 4. Apply log1p transformation (log(x+1)) to right-skewed features: 'miles', 'drive_hours', 'count_brakes', 'count_accelarations', 'time_speeding_hours', 'time_phoneuse_hours', 'highway_miles', 'night_drive_hrs'. 5. Apply StandardScaler to all numeric features: fit on train set, transform both train and test sets. Final feature set after preprocessing: 'month', 'count_trip', 'miles', 'drive_hours', 'count_brakes', 'count_accelarations', 'time_speeding_hours', 'time_phoneuse_hours', 'highway_miles', 'night_drive_hrs', 'maximum_speed'.",

  "experiment_feature_engineering_steps": "1. Create exposure-normalized features to reduce multicollinearity: 'brakes_per_trip' = count_brakes / count_trip, 'accel_per_trip' = count_accelarations / count_trip, 'miles_per_trip' = miles / count_trip, 'hours_per_trip' = drive_hours / count_trip. Handle division by zero by setting result to 0 when count_trip is 0. 2. Create risk behavior ratios: 'highway_ratio' = highway_miles / miles (set to 0 when miles is 0), 'speeding_ratio' = time_speeding_hours / drive_hours (set to 0 when drive_hours is 0), 'phone_ratio' = time_phoneuse_hours / drive_hours (set to 0 when drive_hours is 0). 3. Create composite risk score: 'risk_score' = standardized sum of time_speeding_hours, time_phoneuse_hours, and night_drive_hrs. 4. Keep original features alongside engineered features for model selection. Final feature set includes both original preprocessed features and new engineered features: normalized exposure metrics, risk ratios, and composite risk score.",

  "experiment_model_selection_steps": "1. Primary algorithm: RandomForestClassifier with parameters: n_estimators=200, max_depth=12, min_samples_split=10, min_samples_leaf=5, class_weight='balanced', random_state=42. 2. Hyperparameter tuning using stratified 5-fold cross-validation on train set with PR-AUC scoring: tune n_estimators=[100, 200, 300], max_depth=[8, 10, 12, 15], min_samples_split=[5, 10, 20], min_samples_leaf=[2, 5, 10]. 3. Secondary models for comparison: XGBClassifier with sample weights derived from balanced class weights, GradientBoostingClassifier with balanced class weighting strategy. 4. Ensemble approach: Simple voting ensemble of top 2 performing individual models using probability averaging. 5. Feature selection: Use recursive feature elimination with cross-validation (RFECV) on Random Forest to identify optimal feature subset, minimum 5 features retained. 6. Final model selection based on stratified cross-validation PR-AUC performance on validation splits.",

  "experiment_evaluation_metric": "PR-AUC (Precision-Recall Area Under Curve) - Macro-averaged across classes. Primary metric for model selection and final evaluation. Calculate individual class PR-AUC scores for classes 0, 1, and 2, then compute macro average. For Class 2 with very few samples, report individual metrics but acknowledge limited reliability. Include secondary metrics: F1-score (macro and weighted), precision and recall per class, classification report. Use stratified cross-validation during model development to ensure reliable performance estimates given severe class imbalance.",

  "experiment_evaluation_strategy": "1. Performance Analysis: Calculate macro-averaged PR-AUC as primary metric, report individual class PR-AUC, precision, recall, and F1-scores. Include confusion matrix analysis and classification report. 2. Class-specific Analysis: Detailed analysis of Class 1 (1 collision) performance since Class 2 has insufficient samples. Analyze precision-recall trade-offs and optimal threshold selection for collision prediction. 3. Feature Importance Analysis: Extract and visualize Random Forest feature importances, analyze which driving behaviors most strongly predict collisions. Compare original vs engineered feature importance rankings. 4. Error Analysis: Identify characteristics of misclassified samples, analyze false positive and false negative patterns. Examine prediction confidence distributions across classes. 5. Calibration Analysis: Assess prediction probability calibration using reliability diagrams, particularly important for safety-critical collision prediction. 6. Business Impact Simulation: Calculate potential collision prevention rates at different probability thresholds, estimate false alarm rates. 7. Cross-validation Robustness: Report mean and standard deviation of CV scores to assess model stability across different data splits."
}